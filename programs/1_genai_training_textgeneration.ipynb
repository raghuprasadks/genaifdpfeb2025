{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7LIE3GR-qGA"
      },
      "outputs": [],
      "source": [
        "!pip install openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "tf63wbi-CPid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "luK6BmOsAS_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client=OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "7Mj5WZZD_dA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion=client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\",\"content\":\"You are a helpful assistant.\"},\n",
        "        {\"role\":\"user\",\"content\":\"Who are you?\"}\n",
        "\n",
        "    ]\n",
        "    )"
      ],
      "metadata": {
        "id": "D-Iw54zo_rEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nnJZwWf_u1E",
        "outputId": "9ed86364-5fbe-4369-d1b5-2231d7ad051c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am an AI language model created by OpenAI. I'm here to assist you by answering questions, providing information, and helping with a wide range of topics. How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion=client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages = [\n",
        "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "      {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
        "      {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"},\n",
        "      {\"role\": \"user\", \"content\": \"Great! Can you also tell me its population?\"},\n",
        "  ])\n"
      ],
      "metadata": {
        "id": "c-hoArw2GfN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(completion.choices[0])\n",
        "messsage_content=completion.choices[0].message.content\n",
        "print(messsage_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLzdaSnRGs5T",
        "outputId": "f99d69f2-a0d9-4dc5-db76-4d6f8652fe05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of the most recent estimates in 2023, the population of Paris is approximately 2.1 million people within the city limits. However, if you consider the broader metropolitan area, the population is around 12 million. Please note that population figures can change, so it’s always good to check the latest statistics for the most accurate information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#same program using cohere"
      ],
      "metadata": {
        "id": "lsiwrm-6H7_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KxXyvfSs9Vv",
        "outputId": "dedd1218-f25c-4679-fe02-7f541b28c096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/252.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/252.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/3.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "COHERE_API_KEY = userdata.get(\"COHERE_API_KEY\")"
      ],
      "metadata": {
        "id": "rCcXqKLGEYvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "co = cohere.Client(COHERE_API_KEY)"
      ],
      "metadata": {
        "id": "boQClPqbtO9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = co.generate(\n",
        "    model='command-nightly',\n",
        "    prompt='Who are you?',\n",
        "    max_tokens=300,\n",
        "    temperature=0.75,\n",
        "    # ... other parameters\n",
        ")\n"
      ],
      "metadata": {
        "id": "jzF1yocjtZvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(response)\n",
        "print('Prediction: {}'.format(response.generations[0].text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP6FtpbQtits",
        "outputId": "e97d3ef6-f0bd-428d-cd86-c168bb783169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: I am your virtual assistant, powered by Command, a large language model built by the company Cohere. I'm here to help you by providing thorough fact-based responses to your questions. I'm always learning and evolving, so the more you engage with me, the better I'll become at assisting you.\n"
          ]
        }
      ]
    }
  ]
}